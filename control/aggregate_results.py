#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏ —Å–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–µ –æ—Ç—á–µ—Ç—ã.
"""
import os
import re
import json
import sys
from pathlib import Path
from statistics import mean, stdev
from datetime import datetime

def parse_results_sheet(file_path):
    """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª results_sheet –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
        
        results = {'fio': {}, 'pgbench': {}}
        
        # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        main_start = content.find("–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤:")
        if main_start == -1:
            print(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Ä–∞–∑–¥–µ–ª '–û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤' –≤ —Ñ–∞–π–ª–µ {file_path}")
            return None
            
        # –ò—â–µ–º –∫–æ–Ω–µ—Ü —Ä–∞–∑–¥–µ–ª–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        latency_start = content.find("–î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–¥–µ—Ä–∂–∫–∞—Ö:")
        if latency_start == -1:
            end_pos = len(content)
        else:
            end_pos = latency_start
        
        main_content = content[main_start:end_pos]
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é
        lines = main_content.split('\n')
        current_test_number = 0
        current_test_name = ""
        
        for line in lines:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            if not line.strip() or "Test No." in line or "=" in line or "_" in line:
                continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –¥–∞–Ω–Ω—ã–º–∏
            parts = [p.strip() for p in line.split() if p.strip()]
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
            if len(parts) < 5:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å —Ü–∏—Ñ—Ä—ã (–Ω–æ–º–µ—Ä —Ç–µ—Å—Ç–∞)
            if parts[0].isdigit():
                current_test_number = int(parts[0])
                current_test_name = " ".join(parts[1:-3])
                iops = parts[-3]
                bandwidth = parts[-2]
                latency = parts[-1]
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results['fio'][current_test_name] = {
                    'IOPS': float(iops),
                    'Bandwidth': float(bandwidth),
                    'Latency': float(latency)
                }
            else:
                # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä—ã, —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ç–µ—Å—Ç–∞
                # (–Ω–∞–ø—Ä–∏–º–µ—Ä, Mixed RW –∏–º–µ–µ—Ç –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–æ–º 5)
                current_test_name = " ".join(parts[:-3])
                iops = parts[-3]
                bandwidth = parts[-2]
                latency = parts[-1]
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–æ–º–µ—Ä–æ–≤ —Ç–µ—Å—Ç–æ–≤
                unique_name = f"{current_test_name} ({parts[0]})"
                results['fio'][unique_name] = {
                    'IOPS': float(iops),
                    'Bandwidth': float(bandwidth),
                    'Latency': float(latency)
                }
        
        # –ü–∞—Ä—Å–∏–Ω–≥ pgbench –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        pgbench_pattern = r'TPS.*?:\s*([\d.]+).*?–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞:\s*([\d.]+).*?–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:\s*(\d+)'
        pg_match = re.search(pgbench_pattern, content, re.DOTALL)
        if pg_match:
            results['pgbench'] = {
                'TPS': float(pg_match.group(1)),
                'Latency_Avg': float(pg_match.group(2)),
                'Transactions': int(pg_match.group(3))
            }
        
        return results
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path}: {e}")
        return None

def aggregate_results(results_dir):
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π"""
    results_dir = Path(results_dir)
    
    # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã results_sheet –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
    all_result_files = []
    for file in results_dir.rglob('results_sheet_*.txt'):
        all_result_files.append(file)
    
    if not all_result_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ results_sheet_*.txt")
        print(f"üîç –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {results_dir}:")
        for item in results_dir.rglob('*'):
            if item.is_file():
                print(f"  ‚Ä¢ {item.relative_to(results_dir)}")
        return None
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_result_files)} —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    for file in all_result_files:
        print(f"  ‚Ä¢ {file.relative_to(results_dir)}")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏—è–º
    iterations_data = {}
    num_vms = 1  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –í–ú –∏–∑ –∏–º–µ–Ω–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    dir_name = results_dir.name
    vm_match = re.search(r'_(\d+)vms_', dir_name)
    if vm_match:
        num_vms = int(vm_match.group(1))
    
    for file in all_result_files:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        iter_match = re.search(r'iter(\d+)', file.name)
        if iter_match:
            iter_num = int(iter_match.group(1))
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–æ–º–µ—Ä–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ –≤ –∏–º–µ–Ω–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º 1
            iter_num = 1
        
        parsed = parse_results_sheet(file)
        if parsed:
            if iter_num not in iterations_data:
                iterations_data[iter_num] = []
            iterations_data[iter_num].append(parsed)
    
    if not iterations_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        return None
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    aggregated = {
        'fio': {},
        'pgbench': {},
        'iterations': sorted(iterations_data.keys()),
        'num_vms': num_vms
    }
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è FIO
    all_fio_tests = set()
    for iter_results in iterations_data.values():
        for vm_result in iter_results:
            all_fio_tests.update(vm_result['fio'].keys())
    
    for test_name in sorted(all_fio_tests):
        metrics = {'IOPS': [], 'Bandwidth': [], 'Latency': []}
        for iter_results in iterations_data.values():
            for vm_result in iter_results:
                if test_name in vm_result['fio']:
                    iops = vm_result['fio'][test_name]['IOPS']
                    bandwidth = vm_result['fio'][test_name]['Bandwidth']
                    latency = vm_result['fio'][test_name]['Latency']
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è Mixed RW)
                    if test_name == "Mixed RW (Read)" and iops > 1000:
                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    
                    metrics['IOPS'].append(iops)
                    metrics['Bandwidth'].append(bandwidth)
                    metrics['Latency'].append(latency)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è stdev
        samples_count = len(metrics['IOPS'])
        if samples_count > 0:
            aggregated['fio'][test_name] = {
                'IOPS_mean': mean(metrics['IOPS']),
                'IOPS_stdev': stdev(metrics['IOPS']) if samples_count > 1 else 0,
                'Bandwidth_mean': mean(metrics['Bandwidth']),
                'Bandwidth_stdev': stdev(metrics['Bandwidth']) if samples_count > 1 else 0,
                'Latency_mean': mean(metrics['Latency']),
                'Latency_stdev': stdev(metrics['Latency']) if samples_count > 1 else 0,
                'samples': samples_count
            }
        else:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞ {test_name}")
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è pgbench
    pgbench_metrics = {'TPS': [], 'Latency_Avg': [], 'Latency_Stddev': [], 'Transactions': []}
    pgbench_found = False
    
    for iter_results in iterations_data.values():
        for vm_result in iter_results:
            if 'pgbench' in vm_result and vm_result['pgbench']:
                pgbench_found = True
                for metric, values in pgbench_metrics.items():
                    if vm_result['pgbench'].get(metric) is not None:
                        values.append(vm_result['pgbench'][metric])
    
    if pgbench_found and pgbench_metrics['TPS']:
        samples_count = len(pgbench_metrics['TPS'])
        aggregated['pgbench'] = {
            'TPS_mean': mean(pgbench_metrics['TPS']),
            'TPS_stdev': stdev(pgbench_metrics['TPS']) if samples_count > 1 else 0,
            'Latency_Avg_mean': mean(pgbench_metrics['Latency_Avg']) if pgbench_metrics['Latency_Avg'] else 0,
            'Latency_Avg_stdev': stdev(pgbench_metrics['Latency_Avg']) if samples_count > 1 and pgbench_metrics['Latency_Avg'] else 0,
            'samples': samples_count
        }
    
    return aggregated

def generate_report(aggregated, output_file):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç"""
    report = []
    report.append("="*80)
    report.append("–ê–ì–†–ï–ì–ò–†–û–í–ê–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    report.append("="*80)
    report.append(f"–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(aggregated['iterations'])}")
    report.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –í–ú: {aggregated['num_vms']}")
    report.append("")
    
    # FIO —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if aggregated['fio']:
        report.append("="*80)
        report.append("FIO - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–æ–≤–æ–π –ø–æ–¥—Å–∏—Å—Ç–µ–º—ã (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)")
        report.append("="*80)
        report.append("")
        report.append(f"{'Test Name':<35} {'IOPS':<20} {'Bandwidth (MiB/s)':<20} {'Latency (ms)':<20}")
        report.append("-"*80)
        for test_name, metrics in sorted(aggregated['fio'].items()):
            report.append(
                f"{test_name:<35} "
                f"{metrics['IOPS_mean']:>8.1f} ¬±{metrics['IOPS_stdev']:>6.1f}  "
                f"{metrics['Bandwidth_mean']:>8.1f} ¬±{metrics['Bandwidth_stdev']:>6.1f}  "
                f"{metrics['Latency_mean']:>8.2f} ¬±{metrics['Latency_stdev']:>6.2f}"
            )
        report.append("")
    
    # pgbench —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if 'pgbench' in aggregated and aggregated['pgbench']:
        report.append("="*80)
        report.append("pgbench - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL OLTP (—Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)")
        report.append("="*80)
        report.append("")
        pg = aggregated['pgbench']
        report.append(f"TPS (Transactions Per Second): {pg['TPS_mean']:.2f} ¬± {pg['TPS_stdev']:.2f}")
        report.append(f"–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞: {pg['Latency_Avg_mean']:.3f} ¬± {pg['Latency_Avg_stdev']:.3f} ms")
        report.append(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–º–µ—Ä–µ–Ω–∏–π: {pg['samples']}")
        report.append("")
    else:
        report.append("="*80)
        report.append("pgbench - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL OLTP")
        report.append("="*80)
        report.append("")
        report.append("‚ÑπÔ∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã pgbench –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç (—Ç–µ—Å—Ç –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª—Å—è –∏–ª–∏ –Ω–µ –±—ã–ª –≤–∫–ª—é—á–µ–Ω)")
        report.append("")
    
    report.append("="*80)
    report.append("–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ó–Ω–∞—á–µ–Ω–∏—è —É–∫–∞–∑–∞–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ '—Å—Ä–µ–¥–Ω–µ–µ ¬± —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ'")
    report.append("="*80)
    
    report_text = "\n".join(report)
    
    # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
    print(report_text)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
    with open(output_file, 'w') as f:
        f.write(report_text)
    print(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    return report_text

def save_json(aggregated, output_file):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ JSON"""
    with open(output_file, 'w') as f:
        json.dump(aggregated, f, indent=2, ensure_ascii=False)
    print(f"üìä JSON –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")

def main():
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 aggregate_results.py <–ø—É—Ç—å_–∫_–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏_—Å_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏> [–ø—É—Ç—å_2] ...")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python3 aggregate_results.py results/20251203_1121_iscsi_1vms_2iter/")
        print("  python3 aggregate_results.py results/*/")
        sys.exit(1)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    for results_dir in sys.argv[1:]:
        if not os.path.exists(results_dir):
            print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {results_dir}")
            continue
        
        print(f"\n{'='*60}")
        print(f"üìÅ –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤: {results_dir}")
        print("‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        aggregated = aggregate_results(results_dir)
        if not aggregated:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            continue
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤
        output_base = os.path.join(results_dir, "aggregated_report")
        generate_report(aggregated, f"{output_base}.txt")
        save_json(aggregated, f"{output_base}.json")
    
    print(f"\n{'='*60}")
    print("‚úÖ –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π!")

if __name__ == "__main__":
    main()