#!/usr/bin/env python3
"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
–°–æ–∑–¥–∞–µ—Ç –Ω–∞–≥–ª—è–¥–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–µ–∂–¥—É —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏.
"""
import json
import sys
import os
import re
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
matplotlib.use('Agg')  # –î–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ GUI

# –¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –¥–ª—è —Ç–∏–ø–æ–≤ —Ö—Ä–∞–Ω–∏–ª–∏—â
STORAGE_COLORS = {
    'local': '#1f77b4',  # –°–∏–Ω–∏–π –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    'iscsi': '#ff7f0e',  # –û—Ä–∞–Ω–∂–µ–≤—ã–π –¥–ª—è iSCSI
    'default': '#2ca02c'  # –ó–µ–ª–µ–Ω—ã–π –¥–ª—è –Ω–µ–æ–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö —Ç–∏–ø–æ–≤
}

def get_storage_type(label):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –∏–∑ –º–µ—Ç–∫–∏"""
    label_lower = label.lower()
    if 'local' in label_lower:
        return 'local'
    elif 'iscsi' in label_lower:
        return 'iscsi'
    else:
        return 'default'

def get_color_for_storage(storage_type):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ü–≤–µ—Ç –¥–ª—è —Ç–∏–ø–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    return STORAGE_COLORS.get(storage_type, STORAGE_COLORS['default'])

def load_aggregated_data(json_file):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    try:
        with open(json_file, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {json_file}: {str(e)}")
        return None

def validate_data_for_visualization(datasets):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å"""
    valid_datasets = {}
    test_types_found = set()
    
    for label, data in datasets.items():
        if not data or 'fio' not in data:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç {label}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ FIO")
            continue
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ç–∏–ø—ã —Ç–µ—Å—Ç–æ–≤
        test_types = list(data['fio'].keys())
        test_types_found.update(test_types)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–æ–ª–µ–π –≤ –∫–∞–∂–¥–æ–º —Ç–µ—Å—Ç–µ
        valid_tests = {}
        for test_name, metrics in data['fio'].items():
            required_fields = ['IOPS_mean', 'Bandwidth_mean', 'Latency_mean']
            if all(field in metrics for field in required_fields):
                valid_tests[test_name] = metrics
            else:
                print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω —Ç–µ—Å—Ç '{test_name}' –≤ {label}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è")
        
        if not valid_tests:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç {label}: –Ω–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤")
            continue
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö —Å —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º–∏ —Ç–µ—Å—Ç–∞–º–∏
        valid_data = data.copy()
        valid_data['fio'] = valid_tests
        valid_datasets[label] = valid_data
    
    if not valid_datasets:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        return None, None
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(valid_datasets)} –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤")
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —Ç–µ—Å—Ç—ã: {', '.join(sorted(test_types_found))}")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    standard_tests = [
        "Sequential Write",
        "Sequential Read",
        "Random Write",
        "Random Read",
        "Mixed RW (Write)",
        "Mixed RW (Read)"
    ]
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–µ—Å—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –¥–∞–Ω–Ω—ã—Ö
    filtered_tests = [test for test in standard_tests if test in test_types_found]
    
    if not filtered_tests:
        print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        filtered_tests = sorted(test_types_found)[:6]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 6 —Ç–µ—Å—Ç–æ–≤
    
    return valid_datasets, filtered_tests

def plot_fio_comparison(datasets, filtered_tests, output_dir):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è FIO —Ç–µ—Å—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
    if not filtered_tests or not datasets:
        print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ FIO")
        return
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    metrics = ['IOPS', 'Bandwidth', 'Latency']
    metric_titles = {
        'IOPS': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ IOPS –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏',
        'Bandwidth': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏',
        'Latency': '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–µ–∫ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏'
    }
    metric_labels = {
        'IOPS': 'IOPS (—Ç—ã—Å—è—á–∏)',
        'Bandwidth': 'Bandwidth (MiB/s)',
        'Latency': 'Latency (ms)'
    }
    
    x = range(len(filtered_tests))
    width = 0.8 / len(datasets)
    
    for metric in metrics:
        fig, ax = plt.subplots(figsize=(14, 8))
        
        # –î–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–¥–∞—Ç–∞—Å–µ—Ç–∞)
        for idx, (label, data) in enumerate(datasets.items()):
            values = []
            errors = []
            
            for test in filtered_tests:
                if test in data['fio']:
                    values.append(data['fio'][test][f'{metric}_mean'])
                    errors.append(data['fio'][test][f'{metric}_stdev'])
                else:
                    values.append(0)
                    errors.append(0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            storage_type = get_storage_type(label)
            color = get_color_for_storage(storage_type)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–∑–∏—Ü–∏—é —Å—Ç–æ–ª–±—Ü–æ–≤
            offset = width * idx - width * (len(datasets) - 1) / 2
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
            bars = ax.bar([i + offset for i in x], values, width,
                          yerr=errors, capsize=5, color=color, alpha=0.8,
                          label=f"{storage_type.upper()} ({data['num_vms']} VM)")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –≤–Ω—É—Ç—Ä–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
            for i, bar in enumerate(bars):
                height = bar.get_height()
                if height > 0:
                    # –ü–æ–∑–∏—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –≤—ã—Å–æ—Ç—ã —Å—Ç–æ–ª–±—Ü–∞
                    text_y = height * 0.5 if height > 10 else height + (height * 0.05)
                    text_color = 'white' if height > 10 else 'black'
                    fontsize = 8 if len(datasets) > 2 else 9
                    
                    ax.text(bar.get_x() + bar.get_width()/2., text_y,
                           f'{height:.1f}',
                           ha='center', va='center', fontsize=fontsize, color=text_color)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∞—Ñ–∏–∫–∞
        ax.set_xlabel('–¢–∏–ø —Ç–µ—Å—Ç–∞', fontsize=12)
        ax.set_ylabel(metric_labels[metric], fontsize=12)
        ax.set_title(metric_titles[metric], fontsize=14, fontweight='bold')
        ax.set_xticks(x)
        ax.set_xticklabels([t.replace(' ', '\n') for t in filtered_tests], rotation=15, ha='center')
        ax.legend(title='–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è', loc='upper right')
        ax.grid(axis='y', alpha=0.3)
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ç—Å—Ç—É–ø—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        plt.subplots_adjust(top=0.85)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        plt.savefig(os.path.join(output_dir, f'fio_{metric.lower()}_comparison.png'), dpi=300, bbox_inches='tight')
        plt.close()
    
    print("‚úÖ –ì—Ä–∞—Ñ–∏–∫–∏ FIO —Å–æ–∑–¥–∞–Ω—ã")

def plot_pgbench_comparison(datasets, output_dir):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è pgbench —Ç–µ—Å—Ç–æ–≤"""
    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ pgbench
    pgbench_data = {label: data for label, data in datasets.items() 
                    if 'pgbench' in data and data['pgbench']}
    
    if not pgbench_data:
        print("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö pgbench –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        return
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º —Ö—Ä–∞–Ω–∏–ª–∏—â
    storage_groups = {}
    for label, data in pgbench_data.items():
        storage_type = get_storage_type(label)
        vm_count = data.get('num_vms', 1)
        key = (storage_type, vm_count)
        
        if key not in storage_groups:
            storage_groups[key] = []
        storage_groups[key].append(data['pgbench'])
    
    if not storage_groups:
        print("‚ö†Ô∏è  –ù–µ—Ç –≥—Ä—É–ø–ø–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö pgbench")
        return
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ –æ–¥–Ω–æ–π —Ñ–∏–≥—É—Ä–µ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # –ì—Ä–∞—Ñ–∏–∫ TPS
    x = range(len(storage_groups))
    width = 0.6
    
    for idx, ((storage_type, vm_count), pg_data) in enumerate(storage_groups.items()):
        tps_values = [d['TPS_mean'] for d in pg_data]
        tps_errors = [d['TPS_stdev'] for d in pg_data]
        
        avg_tps = mean(tps_values)
        avg_error = mean(tps_errors) if len(tps_errors) > 1 else tps_errors[0]
        
        color = get_color_for_storage(storage_type)
        bar = ax1.bar(idx, avg_tps, width, yerr=avg_error, capsize=10, 
                     color=color, alpha=0.8, label=f"{storage_type.upper()} ({vm_count} VM)")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ —Å—Ç–æ–ª–±–µ—Ü
        height = bar[0].get_height()
        ax1.text(bar[0].get_x() + bar[0].get_width()/2., height + (height * 0.05),
                f'{height:.0f}',
                ha='center', va='bottom', fontsize=9)
    
    ax1.set_xlabel('–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è', fontsize=12)
    ax1.set_ylabel('TPS (—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ —Å–µ–∫—É–Ω–¥—É)', fontsize=12)
    ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ TPS (pgbench)', fontsize=14, fontweight='bold')
    ax1.set_xticks(x)
    ax1.set_xticklabels([f"{storage.upper()}\n({vm} VM)" for (storage, vm) in storage_groups.keys()], 
                       rotation=15, ha='center')
    ax1.grid(axis='y', alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ –∑–∞–¥–µ—Ä–∂–∫–∏
    for idx, ((storage_type, vm_count), pg_data) in enumerate(storage_groups.items()):
        lat_values = [d['Latency_Avg_mean'] for d in pg_data]
        lat_errors = [d['Latency_Avg_stdev'] for d in pg_data]
        
        avg_lat = mean(lat_values)
        avg_error = mean(lat_errors) if len(lat_errors) > 1 else lat_errors[0]
        
        color = get_color_for_storage(storage_type)
        bar = ax2.bar(idx, avg_lat, width, yerr=avg_error, capsize=10,
                     color=color, alpha=0.8, label=f"{storage_type.upper()} ({vm_count} VM)")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞ —Å—Ç–æ–ª–±–µ—Ü
        height = bar[0].get_height()
        ax2.text(bar[0].get_x() + bar[0].get_width()/2., height + (height * 0.05),
                f'{height:.2f}',
                ha='center', va='bottom', fontsize=9)
    
    ax2.set_xlabel('–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è', fontsize=12)
    ax2.set_ylabel('–°—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞ (ms)', fontsize=12)
    ax2.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ (pgbench)', fontsize=14, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels([f"{storage.upper()}\n({vm} VM)" for (storage, vm) in storage_groups.keys()],
                       rotation=15, ha='center')
    ax2.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'pgbench_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("‚úÖ –ì—Ä–∞—Ñ–∏–∫–∏ pgbench —Å–æ–∑–¥–∞–Ω—ã")

def plot_scalability_analysis(datasets, output_dir):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –í–ú –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    scalability_data = {}
    
    for label, data in datasets.items():
        storage_type = get_storage_type(label)
        vm_count = data.get('num_vms', 1)
        
        if storage_type not in scalability_data:
            scalability_data[storage_type] = {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏
        if 'Random Read' in data['fio'] and 'Random Write' in data['fio']:
            scalability_data[storage_type][vm_count] = {
                'read_iops': data['fio']['Random Read']['IOPS_mean'],
                'write_iops': data['fio']['Random Write']['IOPS_mean']
            }
    
    if len(scalability_data) < 2 or any(len(vm_data) < 2 for vm_data in scalability_data.values()):
        print("‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏")
        return
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # –ì—Ä–∞—Ñ–∏–∫ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ —á—Ç–µ–Ω–∏—è
    x_positions = range(len(next(iter(scalability_data.values()))))
    bar_width = 0.8 / len(scalability_data)
    
    for idx, (storage_type, vm_data) in enumerate(scalability_data.items()):
        vm_counts = sorted(vm_data.keys())
        read_iops = [vm_data[vm]['read_iops'] for vm in vm_counts]
        color = get_color_for_storage(storage_type)
        
        offset = bar_width * idx - bar_width * (len(scalability_data) - 1) / 2
        bars = ax1.bar([x + offset for x in x_positions], read_iops, bar_width,
                      color=color, alpha=0.8, label=storage_type.upper())
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + (height * 0.05),
                    f'{height:.0f}',
                    ha='center', va='bottom', fontsize=9)
    
    ax1.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –í–ú', fontsize=12)
    ax1.set_ylabel('Random Read IOPS', fontsize=12)
    ax1.set_title('–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å: Random Read', fontsize=14, fontweight='bold')
    ax1.set_xticks(x_positions)
    ax1.set_xticklabels(sorted(next(iter(scalability_data.values())).keys()))
    ax1.legend(title='–¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞')
    ax1.grid(axis='y', alpha=0.3)
    
    # –ì—Ä–∞—Ñ–∏–∫ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∏
    for idx, (storage_type, vm_data) in enumerate(scalability_data.items()):
        vm_counts = sorted(vm_data.keys())
        write_iops = [vm_data[vm]['write_iops'] for vm in vm_counts]
        color = get_color_for_storage(storage_type)
        
        offset = bar_width * idx - bar_width * (len(scalability_data) - 1) / 2
        bars = ax2.bar([x + offset for x in x_positions], write_iops, bar_width,
                      color=color, alpha=0.8, label=storage_type.upper())
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + (height * 0.05),
                    f'{height:.0f}',
                    ha='center', va='bottom', fontsize=9)
    
    ax2.set_xlabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –í–ú', fontsize=12)
    ax2.set_ylabel('Random Write IOPS', fontsize=12)
    ax2.set_title('–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å: Random Write', fontsize=14, fontweight='bold')
    ax2.set_xticks(x_positions)
    ax2.set_xticklabels(sorted(next(iter(scalability_data.values())).keys()))
    ax2.legend(title='–¢–∏–ø —Ö—Ä–∞–Ω–∏–ª–∏—â–∞')
    ax2.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'scalability_analysis.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("‚úÖ –ì—Ä–∞—Ñ–∏–∫ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω")

def find_aggregated_reports(input_paths):
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ñ–∞–π–ª—ã —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –≤ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø—É—Ç—è—Ö"""
    report_files = []
    
    for path in input_paths:
        path_obj = Path(path)
        
        # –ï—Å–ª–∏ —ç—Ç–æ —Ñ–∞–π–ª
        if path_obj.is_file():
            if path_obj.name == 'aggregated_report.json':
                report_files.append(str(path_obj))
            continue
        
        # –ï—Å–ª–∏ —ç—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, –∏—â–µ–º –≤ –Ω–µ–π –∏ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
        if path_obj.is_dir():
            for file in path_obj.rglob('aggregated_report.json'):
                report_files.append(str(file))
            continue
    
    if not report_files:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        print(f"üîç –ü–æ–∏—Å–∫ –ø—Ä–æ–≤–æ–¥–∏–ª—Å—è –≤: {', '.join(input_paths)}")
        print("üîç –ò—Å–∫–∞–ª–∏—Å—å —Ñ–∞–π–ª—ã: aggregated_report.json")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        print("\nüìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:")
        for path in input_paths:
            path_obj = Path(path)
            if path_obj.is_dir():
                print(f"\n{path}:")
                for item in path_obj.rglob('*'):
                    if item.is_file():
                        print(f"  ‚Ä¢ {item.relative_to(path_obj)}")
    
    return report_files

def main():
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 visualize_results.py <–ø–∞–ø–∫–∞1> [<–ø–∞–ø–∫–∞2> ...] –∏–ª–∏ <json_—Ñ–∞–π–ª1> [<json_—Ñ–∞–π–ª2> ...]")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python3 visualize_results.py results/*/")
        print("  python3 visualize_results.py results/20251218_1619_local_1vms_2iter/ results/20251218_1722_iscsi_1vms_2iter/")
        print("  python3 visualize_results.py results/*/aggregated_report.json")
        sys.exit(1)
    
    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    report_files = find_aggregated_reports(sys.argv[1:])
    
    if not report_files:
        sys.exit(1)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    datasets = {}
    for json_path in report_files:
        data = load_aggregated_data(json_path)
        if data:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∫—É –∏–∑ –ø—É—Ç–∏
            parent_dir = Path(json_path).parent
            label = parent_dir.name
            datasets[label] = data
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {json_path} -> {label}")
    
    if not datasets:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        sys.exit(1)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    valid_datasets, filtered_tests = validate_data_for_visualization(datasets)
    
    if not valid_datasets or not filtered_tests:
        print("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        sys.exit(1)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
    output_dir = "visualization_output"
    os.makedirs(output_dir, exist_ok=True)
    print(f"\nüìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –≤: {output_dir}/")
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫–∏
    plot_fio_comparison(valid_datasets, filtered_tests, output_dir)
    plot_pgbench_comparison(valid_datasets, output_dir)
    plot_scalability_analysis(valid_datasets, output_dir)
    
    print(f"\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ –ì—Ä–∞—Ñ–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}/")
    print("\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    for file in sorted(os.listdir(output_dir)):
        if file.endswith('.png'):
            print(f"  ‚Ä¢ {file}")

if __name__ == "__main__":
    main()